\chapter{Literature Survey}


\section{Introduction }
\label{sec:Introduction}

A wide variety of techniques were suggested for sketch recognition. Currently symbol recognition is solved as an either image based and feature based or AI-based problem. In image based recognition symbols are recognized based on there goemetrical, structure or other spatial features. 
%The AI based recognition treat the problem as a methods in recognizing symbols mainly imply more time and processing as for the search and rules applied but claims to be more accurate.


%The researchers had divided the sketch recognition problem into Image based and AI Based problem. The next section will discuss the methods used by current sketch understanding system. Firstly, in section \ref{sec:FirstStepSymbolRecognition} Symbol recognition research will be investigated and divided into image based and AI based methods.

 %In section \ref{sec:SecondStep:SketchUnderstanding}, the understanding techniques will be demonstrated. Understanding mainly will handle knowledge representation methods, handling uncertainty and finally how researcher in sketch reduced the sketch search space.

%\section{Symbol Recognition}
%\label{sec:FirstStepSymbolRecognition}
 Only few systems permit the user to freely draw strokes and symbols in any order \cite{Vibratory8,visualpattern43,Cali63,statisticalparsing26,physicalmeaning6}. Those systems must employ a method to identify the strokes that belongs to the same symbol. In\cite{gestureexample12,aideddesgin22,sketchinginterfaces2,sketchinginterfaces2,cognitivesketch18,ewhitboard9}for example the user is constrained to draw each symbol using only one stroke which is not only unnatural but also constrains the type fo symbols that can be drawn. Others, constrain the order or style of drawing a symbol\cite{}.  
 


 
 
 
%   A hybrid algorithm was introduced in \cite{earlyprocess} where different sets of segments are generated based on both curvature and speed dominant points, followed by choosing a segmentation with the least error from a generated hybrid set. However, this system is limited to recognizing only specific simple geometric shapes with a set of low level recognizers. Each low level recognizer is designed to recognize only one geometric shape using spatial and geometric information extracted from input stroke.  Yu \cite{meanshift10} introduced a \textit{feature area} for each primitive and then computed the segmentation error for different types of primitives based on the computed \textit{feature area}. His system achieved good accuracy in simple shapes (square, ellipse,...etc) but did not perform well in complex shapes. Paulson and Hammond \cite{Paleosketch08} introduced a set of low level recognizers that were reported to achieve 98\%   accuracy. However, their system similar to all low level recognizers in the way that it identifies a small set of simple shapes.% A genetic algorithm was used by \cite{CruveDivisionSwarm} to optimally divide digital curves into lines and curves. Chen et al.\cite{CruveDivisionSwarm} uses digital curves scanned from paper as input to the system and did not take advantage of the curvature or local geometric properties of the digital curve.

%A genetic algorithm was used by \cite{CruveDivisionSwarm} to optimally divide digital curves into lines and curves. Chen et al. \cite{CruveDivisionSwarm} uses digital curves scanned from paper as input to the system. Also, they did not take advantage of the curvature or local geometric properties of the digital curve. Yin \cite{PolygonApproximationPSO} used PSO to convert digital curves into polygons, our system adopts  Yin \cite{PolygonApproximationPSO} method and tries to improve it by adding curvature and other local information while segmenting strokes to achieve better segmentations. The next section presents the general particle swarm algorithm which is used in both our segmentation algorithms. % are presented in section \ref{subsubsec:Discreteparticleswarmalgorithm}


%To understand a drawing we need to recognize every symbol in it. Hand-drawn sketches need more processing before it is passed to recognitions algorithms.

Sketch recognition task is divided into three main component: 1) preporcessing, 2) stroke segmenation and symbol or guesture recognition. The next sections presents a survey of each component
 %Firstly, we have to determine how symbols are defined or grouped. Some System implies some constrain on user to defined symbol.
  

\subsection{Pre processing }
\label {sec:preprocessing}
 A stroke is all the points that lie along the path of the user pen from the moment of his pen down to pen up events. Not all those points are important even more, there may be redundance points. Therefore, those strokes will need some preprocessing.
 
The stroke that the user draws are mainly sequences of line segments or/and curves which the any system need to divide them to recognize them easily. The main problem is to do so without constraining the user drawing style. The majority of researchers first use a preprocessing process to identify those segments and the critical points from the user strokes.  
Beside points location information (x, y positions) researcher made uses of the extra information from using digital ink. Some as \cite {mulitstroke5,polygonfeedback31}  used user speed information to detect critical points where it is stated that user slow down at those critical points. Other used curvature and directions data. There was also mentioning using the pressure information.  Thought some \cite {MilitaryCOA37,computationalmodel16,polygonfeedback31}  debated on the importance of the extra information and weather the temporal and speed information is significant.  \cite{polygonfeedback31}  used the timestamp for each point and compute time difference between every two successive point to help him finding corners.
\cite{Overview36} uses the speed and direction information but they use on it a hybrid average based filtering to filter noise and unwanted false data from appearing in the data. Finally, they use that information to get a poly line approximating.
 
 
\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/dirspeedgraph.eps}
	\caption[Direction and Speed]{direction and speed graphs of the rectangle stroke the minima in the graph show the location of the corners of the rectangle.}
	\label{fig:dirspeedgraph}
\end{figure}

\cite{Mathpad46}Handle rotations invariant using polar transformation then shifting to make it more reliable when template matching. However, they state that the only problem to there system is that the points near the centroid affect the polar transformations which will effect the matching. %(To solve it they say that loosing the weight of the pixel near the centroid will improve classification).

The next sections will demonstrate firstly the noise removal algorithms and techniques. Then next sections will show the most used critical points detection algorithms along with the segment division algorithms. 


  In\cite{sketchRead29} they divided user strokes into geometric primitives based on some critical points they computes.  After that, they either cluster segment to form a symbol   or directly apply some kind of basic symbol recognition leaving the compound object for next processing step .
  
From the image-based view the symbol is a sequences of line segments or/and curves. To do so without constraining the user drawing style we have to easily divide the user drawn strokes.

%\begin{figure}
%	\includegraphics[scale=0.6]{../../neededfiles/Figures/shapesegmentation.eps}
%	\caption[segmented shapes]{example of Segmented shapes}
%	\label{fig:shapesegmentation}
%\end{figure}


\subsubsection{Removing noise}
\label{sec:RemovingNoise}

 

Due to the sloppiness of the user, his stroke may need a lot of noise removal before any algorithm can extract its features. For example, when a user draw sketches he may over trace the stroke more than one time. Human perception can easily differentiate what exactly is drawn. Nevertheless, for an AI program this is more difficult problem. The user may also overshoot see \textit{Fig\ref{fig:Overshootandundershoot}} or undershoot while drawing intersecting segments. 
\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/Overshootandundershoot.eps}
	\caption[Neat and Sloppy symbols] {The Figure show a sloppy strokes with under shoot and overshoot problems and the neat version of the symbol.}
	\label{fig:Overshootandundershoot}
\end{figure}


 \cite {overtraced24} tried to solve the over traced strokes. they used a thinning algorithm to move points perpendicularly towards the regression line from the formed from fitting line of neighbour's into line or circle or ellipse which is calculated with least square fit for the data. The next step is selecting near neighbours and connection then which gives a serious of linked edges which a greedy link edge algorithm this produce a single stroke instead of over traced see \textit{Fig [\ref {fig:overstroked}]}.

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/overstroked.eps}
	\caption{Example of an overstroked stroke}
	\label{fig:overstroked}
\end{figure} 
Some systems as in \cite{SmartSketch56} where the noise reduction is done in two steps the first step is the polygonal approximation to remove non critical points in the user stroke. The process is mainly removing the redundant points that are along the path of stroke. Due to the shaky nature of user stroke, there are additional end-points at the stroke segments. Secondly, the next step will be applying an Agglomerate point filtering.  Agglomerate filtering is according to \cite {statesurvey35} removing the undesired extra points that is produced due to the unsteady operations produced while lifting and touching tablet.  The results of those processes are passed to final end-point refinement to merge or remove any redundant points.

In \cite{meanshift10,domainindependent17}, Bo Yu uses mean shift procedure as a noise remover and preprocessing step to the recognition step. The mean shift procedure is simply shifting the point to the average of its neighborhoods so smoothing out the noise without changing the global structure of data.  This process is clamed to help find critical points easily after that.

In \cite {domainindependent17}    approximation step uses the speed, curvature, and direction of strokes drawn by user to determine the location of vertices to gain more resistance to noise that data may contain. 


\subsubsection{Critical points and corners Detection}
\label{sec:CriticalPointsAndCornersDetection}

Locating the critical points is provided to the next process of the systems which in most cases segment detection algorithm as in \cite{Simusketch51} . Other systems after detecting the points the system directly uses those information to template matching.

Generally, the critical points along with the segment points of the path from one critical point to another are used to detect labeling of that segment. 
Line detection or multi line segments algorithm is found in \cite{polygonfeedback31} . Mostly after detecting the vertices if the segment cannot be labeled as arc it is defined as a line. Other mainly defines a threshold value of the slope if it increase than that it is counted as an arc.

Systems like \cite{physicalmeaning6} detect critical point for each stroke then the final point is merged with the first if they are in range defined by threshold. However, stroke may also intersect with other strokes drawn before therefore \cite{physicalmeaning6}  introduced a structure to detect such approximates he first define every stroke drawn as series point and labeled as line, arc or area. Then after labeling most strokes the system check for proximity on bases of line -line, line-end point, or line- area. 


In   \cite {meanshift10,domainindependent17}   approximation step uses the speed, curvature, and direction of strokes drawn by user to determine the location of vertices to gain more resistance to noise that data may contain. They firstly analysis the curvature and speed data and use the mean of data as the threshold then use that threshold to separate data into regions and finally locating the maxima and minima in each region . The previous step generates a set of vertices and its certainties they use to choose best fit.

\subsubsection {Primitive stroke segmentation and clustering}
\label{sec:Primitivestrokesegmentationandclustering}

The most segmentation method is least square method in \cite {overtraced24}. Other systems  approximate a line segmented using the information from the direction curve where the curve is fitted with horizontal line. firstly the system compute least square fit for direction curve or the stroke point computed and check if deviation points is small if they pass then hypothesize al line segment  from the first point to the last one. 

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/rectanglerecog.eps}
	\caption{rectangle recognition}
	\label{fig:rectanglerecog}
\end{figure}

%//Other like \cite {tobeadd}  uses the relaxation process to try to relax parameter on a classification .//
 In \cite {meanshift10,domainindependent17}  Bo first uses the direction graph to check if the stroke can be approximated as a line or no. If the stroke can't be approximated as a line it is checked to be a circle or ellipse. the procedure is simply assume a circle classification then check this assumption with the user drawn stroke given a min error range.  
\cite {Fluid25} Trying to combine fast morphing and basic recognition for the sketch drawn as the user draw it. It tries to move the points of strokes drawn by the user draw into one of the known shapes (ex: box, lines and circle). It uses a relaxation and least square method for circles and uses the string of forces for finding best-fit box.

The noise removal and critical point detection is only a preprocessing step for the symbol classification algorithms. Some system implements a segment segmentation and clustering to help in the classification problem. 

After the strokes are segmented \cite {sketchunderstanding1,HierarchicalParsing7,Simusketch51}  proposed a merging techniques that will merge strokes together into symbols to help classification. They use a method combine between divide and merge. They firstly divide the drawn sketches into section based on marker technique they used. After that they merge strokes if there bounding boxes intersects and then  merge generated cluster till no more merge can occur on one segment.

%Intension exteraciton in paper Intention54
% Check to add 

%/*Mathpad46
%methion  check stroke clustering.  Simusketch51  and in 8 
%
%Bo \cite {tobeadd}   The ellipse or

 
\subsubsection{Image and Statistical Features calculation}
\label{sec:ImageandStatisticalFeaturescalculation}


Most system calculates the general image properties for the strokes. Most used features are bounding box, width, size, points along path. 
\cite {meanshift10,domainindependent17}  introduced a new feature which they named "Feature Area which" they used in primitive classification introduced before. They first make and assumption for classification and compute the difference. For example if they make assumption as a circle they first calculate the center of the circle then its radius based on the bounding box of the stroke. The area difference between the computed circle and the current stroke is the feature area. see \textit{Fig\ref{fig:featurearearc}}. 

\begin{figure}


		\subfigure[Feature area of line] {\includegraphics[scale=0.7]{../../neededfiles/Figures/featureareline.eps}}
		
	\subfigure[Feature area of an arc]{	\includegraphics[scale=0.7]{../../neededfiles/Figures/featurearearc.eps}	}
			\caption[Feature area]{the shaded are shows the difference between the computed feature area and the assumption area. }
	\label{fig:featurearearc}
\end{figure}

 System that uses statistical classifiers use other features for each stroke. Features like center of gravity\cite{gestureexample12,sketchunderstanding1}, maximum length line, Zenerik moments \cite{zernike61}, number of lines, curvature angles, minimum enclosing rectangle\cite {incrmentintention41} , convex hull were calculated in \cite {Cali63}.  Also \cite {geometrydomain49} introduced a new feature which he named ink density that he used in the classification of the glyphs see \textit{Fig \ref{fig:inkdensity}}. 
\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/inkdensity.eps}
	\caption[Statistical Feature Example]{The figure shows the Ink Density feature that \cite{geometrydomain49} introduced. }
	\label{fig:inkdensity}
\end{figure}
All spatial relationships needed in the graph or template matching is computed after statistical features are calculated. Relations like intersections, containment, perpendicular, right-of, left-of and below are the most used relations concerning constructing graphs for symbols\cite {geometrydomain49,sketchinginterfaces2} .%stretchdiagrammer4,     i dont know where is this refrence now 


\subsection{Image Based Classification}
\label{sec:Image Based Classification}

In the following sections, systems generally try to recognize the strokes user draws and give it a label based on there image features. The information collected and features computed in the previous step.
 \subsubsection{Low Level Analysis}
\label{sec:Low Level Analysis}

%
%Detecting object using low level analysis only 
%\cite {mulitstroke5} first detecting vertices and control points then fit these segment into line and arc using best fit and least square error classification.
	

%Check the DB




% description[4] after that it passes through the curve approximation into the Bezier curves
%
%\cite {statesurvey35} we need to fit and filter the classified shapes that is done using on of the following least square is the most frequently method used some use fuzzy logic to make circular fitting some use b-splines or ellipse and circle fitting. some after that do some  shape beatification or regularization.

 
The most used method in low level recognition is best fit and least square methods where they was used in most systems. Other systmes like \cite{polygonfeedback31} prefered to implement its own polygon recognition algorithm.

Bo et al. In \cite{meanshift10} introduced an algorithm to recognize line and arcs.  The system used the direction graph and fitted stroke points with a non horizontal line. So the recognizing is done using the following algorithm which is preformed before the mean shift procedure so not the destroy the direction graph .Firstly, if direction graph can be approximated using a line then it is recognized as a line. Otherwise the algorithm Bisect the line from the first and last  point of stroke and donate it as "M". Then calculate the intersection point of the line "M" and original stroke and donate it as "A" . Now using the three points first , last points of stroke and point A find the center of circle which passes through all of them which will donate the candidate arc. Finally , calculate the radius of the circle and the mean of distance  between center and each point of stroke and  compute the feature area of the stroke and the circle arc see \textit{Fig \ref{fig:featurearearc}}.
%//


\subsubsection{Template matching}
\label{sec:Template matching}


Template matching is the most used method to recognize strokes and symbols into classes.  Image based template stored on the database is matched with the one user draw to find the correct classification of the strokes drawn.  In most cases, the stroke template is stored as image bitmap \textit{Fig \ref{fig:template}}in the database when the user draws the symbol it is matched using classifiers. \cite {imagetrainable48,HierarchicalParsing7}  used four kind of classifiers to detect the matching template. He used two classifiers to measure similarity and two classifiers to measure dissimilarity then combine them to find best match of drawn stroke from the database.

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/template.eps}
	\caption[Template matching]{Examples of image templates used to match symbols in \cite{imagetrainable48}. }
	\label{fig:template}
\end{figure}

To refine the matching procedure and create more robust classification \cite {imagetrainable48}  first transform the strokes into polar coordinate then match the transformed stroke with the templates in the database. They claim that enhance the classification procedure as the polar coordinate system due to its definition make the stroke more robust to transformation and rotation.

\cite{templatefrag21}  Introduce new way to match stroke temples. He store template as a sequence of lines and ellipse.  When the user draws a stroke the system, segment it into a sequence of lines and ellipse. The system then matches the stored sequences with computed one to find correct classification.

The main problem of template matching is that in most system the templates are hard coded inside the system and cannot be modified at runtime.


\subsubsection{Graph matching}
\label{sec:Graph matching}

Representing the symbol that the user draws as a graph transforms the classification problem into a graph-matching problem. In general, each user stroke is represented as a node of the graph and the relations between those nodes are represented as arc. To classify the symbols the graph constructed must be matched with the graphs in the database.

\cite{physicalmeaning6} uses spatial relationships for there graph matching. They first calculate spatial proximity relationships. Relations like intersections, containment, perpendicular, right-of, left-of and below are the most used relations concerning constructing graphs for symbols.  

Other systems  first analysis the spatial relationship between glyphs (sequence of strokes) using a library of spatial relations and information calculated in the preprocessing step.  After that, they filter out important relation-using hierarchy of rules and type of geometrical constrain. All redundant constrains and relations are removed the final graphs is matched with the database. If more than one candidate is available the algorithm choose the best fit but if no matches found constrains are relaxed and strokes are passed again to classifier.

 Proposed a structure representation of the strokes in \cite{sketchunderstanding1,HierarchicalParsing7} . She added ratio of proximity of the relations between strokes. In addition, she used an error-driven, stochastic search algorithm for graph matching. 




\subsubsection{Statistical methods}
\label{sec:Statisticalmethods}

The application of Statistical classifiers in recognizing shapes are widely used in sketch recognition. Statistical classifier requires training time before the recognition actually happen. Then first step of classification is features computation that is done in the previous step. Finally, the recognition of symbols will be based on the classifier and the training set used.  

One of the first systems in sketch recognition is \citep{gestureexample12,aideddesgin22} algorithm to recognize ink gestures. He used Gaussian statistical classifier to classify any stroke user draw.  In \cite {gestureexample12}  he firstly compute statistical information about the user stroke then pass it to a Gaussian classifier that had been trained using 10-20 samples. The output of the classifier is classification of the stroke from one of the known classes.

Bayesian classifiers was used in \cite{Vibratory8} as a stroke classifier to recognize different shapes. The recognition is done using feature based statistical Gaussian distribution and Bayesian classifier techniques. The trainer use nine features extracted from segmented symbols (ex number of line segments, number of L intersections, ) all feature has a tolerance within. After all nine feature are computed a Gaussian statically model is constructed.
 
Some systems employ more than one statistical classifier to get better results for the recognition. For example \cite{zernike61} uses Neural network, SVM (support vector machine )and MMD. \cite{polygonfeedback31}
%the closed shaper recognizer which is done using classifiers (SVM , Rule based and ANN ) to make a 
%classification of triangle, rectangle or ellipse

\subsubsection{Other hybrid methods}
\label{sec:Other hybrid methods}

Due to the complexity of the sketch recognition problem, more than one system proposed a hybrid method to solve those problems. They combine more than one approach to recognize symbols the user draws.
\cite{sketchunderstanding1,Simusketch51}  used four kind of classification image, graph matching, statistical and structure based classifiers. Each symbol will contain all graph, statistical, structure information and a (Wight, recognizer) tuples to determine which recognizer has the most influence in recognizing this symbol see \textit{Fig\ref{fig:structuralscemanticdeff}}.
\begin{figure}
	\centering
		\includegraphics[scale=0.5]{../../neededfiles/Figures/structuralscemanticdeff.eps}
	\caption[Structure definitions]{Example of the structure definition of sin symbol in \cite{sketchunderstanding1}.}
	\label{fig:structuralscemanticdeff}
\end{figure}

\cite {HMM53}  firstly normalize the stroke and compute all the statistical features from it. After that, a noise reduction algorithm is used on the strokes which will be translated to produce size and rotation invariance data. Those data is passed to a multistage hybrid recognizer. The first step of his multistage classifier is dynamic programming procedure to compute the optimal degree of similarity and differentiation of symbols. Secondly, a statistical feature ranking is employed on the data produced. Finally, the system will reject all unlikely classification and produce best fit for this stroke using a dynamic programming using domain and context knowledge as input.

\cite{statisticalparsing26} is a statically parser make use of the stored rules and probability of drawn stroked and uses Bayesian classifiers to do the classifications.


\subsection{AI based Classification}
\label{sec:AI based Classification}

Most system mentioned before use image or statistical feature based on the points the user draw. The next few sections will present methods that will use AI approached to classify the symbols the user draw.  Systems using AI approached imply a higher level of understanding of the strokes the user draws. Some construct a graph schema of the symbols from strokes the user draw. Other tried generating a visual grammar to identify the symbols that can be drawn.


\subsubsection{Graph Searching }
\label{sec:Graph Searching }

\textit{Figure \ref{fig:squarescematic}} shows a semantic graph that is constructed by the trainable recognizer in  \cite{mulitstroke5} for a rectangle. The trainable recognizer construct the semantic network at train time with then match the symbol user draw with the networks in the database. To match the networks quickly the system assume the user draws the symbol with the same order as in training set. A deep heuristic graph search will be employed if there was no match found.

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/squarescematic.eps}
	\caption{square scemantic graph}
	\label{fig:squarescematic}
\end{figure}


\cite{SRGraph57}  Uses two kind of graphs relations a spatial relationship graph (SRG) which is build on defining the spatial relationship between the source object and candidate object on the sketch. The relations are defined using Spatial Adjacency Relation (SAR) that falls into relation previously computed in system.   To make the graph fully descriptive the system computes Relative Position Relation of SAR relations and adds these relations into the SRG graph.

\subsubsection{Rule based }
\label{sec:Rule based }


The general algorithm of rule based system as used in \cite{interpretationmechanical50,SmartSketch56}  based on a knowledge of relation ship between nodes (strokes) a role is defined using those relation ships. The rule based system check the strokes the user draw against all strokes to detect if there a rule match the drawn symbol. When a rule matches the consequence of this rule, apply on the input symbol.


The rule system used in \cite{sketchinginterfaces2}  uses the (UI user interface) domain knowledge to do its basic recognition. It is divided into two step first is testing if the rules applies on the input symbol. Second step, is ranking the rules that apply on the symbol based on the highest confidence that was given to this input symbol.

Some system like in \cite{SmartSketch56}  used the rules to help in noise removal. Furthermore, rules based system are used to employ some reasoning to the recognized symbols with the help of context knowledge \cite {interpretationmechanical50}.

\subsubsection{HMM }
\label{sec:HMM }

 The main idea of HMM is representing knowledge and recognition in serious of states each state has its input conditions. Only a node that has the input conditions of the destination state that can transit it from one state to another. The final state is the recognition state of a given class. For example to recognize a rectangle the first state should be first line detected, second will be second line and the condition is the recognition of either a perpendicular line or parallel line to first one to another. 


In sketch, recognition HMM was used to recognize symbols to different classes. Each class recognized was modeled using a single HMM model. The system in \cite {HMM53} encode the geometrical primitive that construct the symbol the user draws. After the encoding the codes are passed to HMM based classifier. Each object is represented by a HMM model and to manage multiple classes they combine matching score from different HMM models. 



\subsubsection{Graph language and visual language describing }
\label{sec:Graph language and visual language describing }


Researchers tried to generate a visual language that can describe hand drawn sketches. In such systems, sketch recognition will be a question of parsing the sketch document into recognizer that parse strokes according to the constructed grammar. 

Researchers proposed more than one visual grammar to use it in sketch recognition. \cite{statisticalparsing26} proposed a language parser that will parse sketched strokes using grammars rules that was constructed . The system first construct a parser that will parse drawn strokes into tokens then formulate those tokens using the grammar rules stored. Parsing is done in two steps; Firstly, the system should accept input of strokes then it use a statistical parser to generate the parse tree. The statically parser make use of the stored rules and probability of drawn stroked and uses Bayesian classifiers to produce the parse tree. 

%\citep*{XPGParser59} i need author   
Introduced a grammar they called an extended positional grammar (XPG) that is based on XpLR parsing methodology \cite{XPGParser59} . The XPG imagine the symbol with a set of attribute as a sentence that can be parsed using the physical, syntactic and semantic information in sketch. They divided the grammar into two kind the first is named ink grammar, it define the symbol of the language as a composition of primitive geometric shapes. The second is language grammar that they use to identify the sketch as a composition of shapes defined by the ink grammar relation. The parsing itself is done using a incrementally bidirectional parsers. They also add a sketch editor to the system to help user to add new symbols and generate its XPG grammar for it \textit{(see Fig[\ref{fig:symboleditor}])}.


\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/symboleditor.eps}
	\caption[symbol editor]{The Figure shows the symbol editor that\cite{XPGParser59} uses to generate grammar rules.}
	\label{fig:symboleditor}
\end{figure}

Relational grammar was also used to help in reducing the ambiguity with the help of fuzzy logic\cite {visualpattern43} . The fuzzy set is used to resolve the visual relations of the sketched stroke with others strokes. Spatial relations like (left of, right of) are computed and then passed to the fuzzy sets. The fuzzy set associate a degree of certainty to the shape defined. 
%EfficientAbstract39 also used the grammar language ladder
\cite{Ladder30,GenericHMM28}  Used visual description language which will generate the information of the structure and constrain of each object classified. The system automatically generates java code for the recognizer for each object. The generated code cycles through the strokes drawn to check if any of the recognizers generated had interpreted any symbols partially or completely. HMM network is used to partially segment the strokes drawn to help the recognition process. 

Similar system was constructed in \cite {Ladder30} , where language grammar is written to descript complex shapes ( see \textit{Fig\ref{fig:arrowladderdef1}}) form primitive geometrical, constrains and triggers. The grammar is then passed to "jess" a java rule bases system that produce java code used in recognition of  drawn strokes.

\begin{figure}
	\centering
	\begin {center}
		\subfigure{An Arrow}
			\centering

			{\label {fig:arrow1}\includegraphics[scale=0.75]{../../neededfiles/Figures/arrowladderdef1.eps}}
		\subfigure[Arrow grammar definition]{\includegraphics[scale=0.88]{../../neededfiles/Figures/arrowladderdef2.eps}}
		\end {center}
	\caption[Arrow definition]{The figures show and regular arrow with 2 shafts and head and its definition in Ladder language \cite{Ladder30}}
	\label{fig:arrowladderdef1}
\end{figure}




%\subsubsection{Fuzzy classifiers }
%\label{sec:FuzzyClassifiers}
%Fuzzy classifiers is used to help in identifying degree of certainty given to certain interpolation the 




\subsection{Hybrid Systems}
\label{sec:Hybrid Systems}

Given that the sketch recognition of hand drawn strokes is exceptionally challenging problem the researcher tried to take advantage of additional of combining approaches to achieve higher recognition rate.

Most of the problems of the sketch recognition are not still addressed. To do so, The sketch recognition system must maintain reliably interactive and extensible interface.  The users minor change can cause the recognizers to fail. The user sloppy drawing with over or/and under shoot strokes  \textit{Fig\ref{fig:overstroked}}. Over processing of data and interaction with background are still major problems in the sketched documents.  

To solve some of these problems,\cite{threeproblmes23}  revealed a two stages recognizer that will firstly construct a data graph in which strokes will be added. After constructing the full data graph the recognizer compute all possible solutions and reject any inconsistent alternatives. Second stage, Employs a topology structure based on the geometrical matching using a CSP making use of sub graphs.  

As mentioned before,\cite{visualpattern43,Cali63} combine fuzzy logic sets with language grammar to create more robust classifiers. Grammar rules are used to describe the spatial relationships of the strokes. Fuzzy sets are used to handle the uncertainties of the relation and classification. Therefore, by combining Fuzzy set and spatial grammar rules the system was able quantify the spatial and statistical attribute calculated before in \ref{sec:Statisticalmethods} from the drawn symbols. 

Also the use of HMM with generated visual grammar was introduced in the system by \cite{HMM53} where they use HMM as a stroke segmentor and pass the output to the visual parser. furthermore, \cite{SmartSketch56} used more than one recognizers to recognize closed shapes rule based approach with hypothesis and test strategy, Neural network and SVM.

\paragraph{Dynamic programming}
\label{sec:DynamicProgramming}
 was used by \cite {Mathpad46,templatefrag21}  to calculate the optimal degree of different and similarity of symbols. The system also uses a dynamic programming procedure to find a best fit from the given set of classifications. 

%\section{Second Step: Sketch Understanding}
%\label{sec:SecondStep:SketchUnderstanding}
%
%
%Sketch understanding is concerned with converting a set of recognized symbols into a whole document that is fully consistent with each other. Mainly the recognized symbols are a list of best candidates of that symbol for which the sketch understanding process must choose best fit based on the document structure.
%
%
%After recognizing the symbols drawn, Understanding the sketch document involve additional processing. In spite of various recognition systems that had reached a satisfactory symbol recognition. The sketch understanding problems are at a standstill. 
%
%
%The recognized symbols must be verified with the rest of the document to fully understand the whole sketch. Consistency, ambiguities and uncertainty of the recognized symbols are the major issues that rise in any sketch understanding system.  
%Most recent sketch understanding system uses more than just the context knowledge that is always available. Domain knowledge \cite {geometrydomain49}, Speech and verbal description of drawn sketch was used in\cite {speechMulti27}.Some verbal description of the drawn symbol helps in creating the casual model for each symbol. 
%
%In the following sections, the ambiguities and uncertainty of sketch understanding systems will be discussed. Followed by how those systems represented knowledge that they use to formulate the understanding process.
%
%\subsection{Handling uncertainty and ambiguities }
%\label{sec:Handlinguncertaintyandambiguities }
%
%The main tasks of the sketch understanding are to handle higher-level ambiguities of the sketch drawn and to manage uncertainty of the recognized symbols. After the user draw a symbol using a single or multi-stroke symbol the recognizer labels each symbol with a known class either low level interpolation or high level. Low level interpolation means simple geometrical shapes and high level means more complex domain specific. Most current recognizers return a list of acceptable label for each symbol. The role of the sketch understating is converting such list of acceptable labels into one interpolation based on the surrounding symbols. They do so with preserving the sketch consistency of interpretation, which means that, the whole document has the same interpretation.  
%
%The next section the various methods that was recently employ to completely understand sketched documents. 
%
%\subsubsection{Rank and prune based on classifiers}
%\label{sec:Rankandprunebasedonclassifiers}
%
%The most used method in understanding the whole document and reducing the inconsistent solutions is the typical method of ranking the solutions and then pruning unwanted ones. 
%Initially the symbols nodes are initialized by all possible pairs of interpolation of the two symbols then the Consistency checker eliminate all inconsistence pairs. \cite {tobeadd} \cite {geometrydomain49}  firstly recognize all possible interpolation then prune and reason using knowledge to get a score for each interpolation. The final step is resolving and choosing the best result.
%
% \cite {Alvarado2002Framework11,HierarchicalParsing7}  First uses a bottom-top search to look for the interpolations of the strokes drawn. A top bottom search is used to prune out incomplete interpolations that was generated in the previous step.  The top bottom firstly checks what symbol may be missing in the current document context after that it prune inconsistent interpolations.
%\subsubsection{Constrain satisfaction methods}
%\label{sec:Constrainsatisfactionmethods}
%
%Constrain satisfaction is the most used method for converting a group of recognized symbols into an understood document. Most recognizers produce a ranked set of possible interpolations. The problem is to constrain theses interpolations to get a total  understanding of the sketch document. Some like in \cite {tobeadd}  use constrain satisfaction methods to apply rules and constrains to match interpolations and rules. Constrains must be carefully written to check that they are not rough or severe. \cite {tobeadd}  checked the constrains applied on this system and if they produce no match the system relax the constrain and runs again with more loss constrains till it find the correct interpolations. 
%
%\begin{figure}
%		\includegraphics[scale=0.7]{../../neededfiles/Figures/CSPphysical.eps}
%	\caption[Physical Constrains on Symbols]{ The figure shows two nodes and the constrain applied on both nodes to detect the inconsistency in the interpretations \cite{physicalmeaning6}. }
%	\label{fig:CSPphysical}
%\end{figure}
%
% \cite {physicalmeaning6}  firstly try connection between symbols firstly using bounding boxes of the symbol to locate the intersecting symbols. The intersected bounding boxes are checked again for ten different types of connection approximately for each terminal of the symbol. After identifying which symbols are connected the problem is identify which interpolation make those connected symbols has physical meaning. This is a "constrain satisfaction" problem the system used two processing steps to solve it. Firstly, the system checks the consistency of node where the node in graph is connection between two adjacent symbols. That means that each two connected symbol are checked and every inconsistent interpolation is rejected and deleted. This generate a local consistent sub graph but there may be a global inconsistent which take us to the second step where the algorithm search the arc consistency. The arcs of the consistency graph are any pair of nodes that have a symbol in common.  Each consistency arc is checked for local and global consistency. This step is applied iteratively till all consistency are cancelled and only one global interpolation is reached \textit{(see Fig[ \ref{fig:CSPphysical}])}. 
% 
% The use of constrain satisfaction has also helped in minimizing the search \cite {tobeadd} . The strokes are incrementally processed using the Constrain system which check for constrain between image feature. Each new stroke either a new partial interpolation is created or an old one is extended and cloned provided that no constrained is violated. 
%
%
%\subsubsection{Bayesians networks}
%\label{sec:Bayesiansnetworks}
%
%
%Since the problem of deciding the best interpretation of a set of valid ones is a certainty problem researchers tried to solve it as a one. Bayesians networks were used to represent certainties in sketch documents\cite{SketchRead2007} .Bayesians classifiers were also used to help the understanding problem in various ways.\cite{statisticalparsing26}  Used Bayesians classifiers to help the statistical parser to recognize the best candidate based on the system rules.
%
%\cite{Alvarado2002Framework11,SketchRead2007} is a complete sketch-understating framework that used top bottom and bottom up search of interpolation of the strokes. The system represented uncertainty using Bayesians networks. Each compound object is represented by a network in which the object is the root \textit{see Fig[\ref {fig:anddefnetwork}]}.
% \begin{figure}
%		\includegraphics[scale=0.7]{../../neededfiles/Figures/anddefnetwork.eps}
%	\caption[Bayesian network]{Bayesian network of an And Gate as defined in \cite{Alvarado2002Framework11}}
%	\label{fig:anddefnetwork}
%\end{figure}
%
%\subsubsection{Other Methods}
%\label{sec:OtherMethods}
%
%Other Method were used in \cite{agent47,sketchinginterfaces2}to understand the sketch documents . For example \cite{sketchinginterfaces2} defined  visual and domain rules that applies on the sketch to finally understand the whole document. \cite{agent47} used software agents to resolve the conflict in curve matching algorithms he used. In addition to agents that resolve the conflict he also used agents to search for applicable features on the strokes. The agent will either report a feature on the strokes drawn or disappear till new strokes are drawn. 
%
%\subsection{Representing knowledge }
%\label{sec:Representingknowledge }
%
%
%Representing knowledge is the one of the challenges that faced the researcher in any AI program. In sketch recognition and understanding, the knowledge can be from more than one resource. The real problem is not to dump the program in too much data knowledge that is unstructured or unused in processing. To do so, means that the system is exhausted in undesired and unfulfilled processing. Processing time in sketch understanding system must be as close to real-time as possible to preserve the user interaction with the system. Therefore, the knowledge must be represented in special method that insures high speed and accuracy of understanding of the drawn sketch.
%
%Systems tried to make uses of more than one kind of knowledge to help in there recognitions and understandings. Spatial and visual knowledge of the drawn symbols are widely used in the sketch systems that relies on grammar languages \cite{GenericHMM28,statisticalparsing26,SketchRead2007} . Speech and multimodal systems helped the recognition of the symbols and reduced the search space.  Domain and grammar knowledge were also used in \cite {geometrydomain49}  .
%
%
%Black board architecture \cite {blackboardur} was widely used to represent the various source and forms of data in the sketch understanding systems. In \cite {Alvarado2002Framework11}  black board was used to represent incremental knowledge which increase by each symbol drawn in the sketch. The black board architecture is simply a modeling of group of people trying to solving a problem. When any one of them find new information he write it down on the black board soon all information will be in the black board for all solver to see and add.
%
%\subsubsection{	Spatial and Visual knowledge}
%\label{sec:SpatialandVisualknowlege}
%
%The visual and spatial information of the drawn symbols with respect to other symbols in the sketch helps in identifying the relation of these symbols with each other.  Those information was used in \cite {Cali63,visualpattern43,incrmentintention41,geometrydomain49,marksacts40,sketchinginterfaces2,captureknowledge19}  to help the recognition and understanding of sketch drawn. 
%
%\cite{SRGraph57}  Introduced a new spatial relationship graph to represent those spatial relation of one symbol to the other. The Spatial relation graph is build from the sketch drawn using primitive spatial adjacency relation and relative position relation.  The produced graphs are then matched using a graph-matching algorithm with the database of graph to recognize best fit. 
%
%The spatial and visual information are used in \cite{XPGParser59} to help in building a parser that will parse the sketch document into symbols and objects. 
%
%\subsubsection{Domain and Context knowledge}
%\label{sec:DomainandContextknowledge}
%
%\begin{figure}
%	\centering
%		\includegraphics[scale=0.8]{../../neededfiles/Figures/domainexamples.eps}
%	\caption[domain examples]{Examples of sketched documents from different domains}
%	\label{fig:domainexamples}
%\end{figure}
%
%Users can draw sketches in different domains \textit{see Fig [\ref{fig:domainexamples}]}and Until now there have not been a sketch understanding system that can identify drawing in any sketched domain. To do so, the system must be multi-domain system and employ a kind of domain identification or classification.  Current systems uses domain and context knowledge to assist in the understanding procedure\cite {geometrydomain49,RetargetableInteractive58,sketchunderstanding1, HierarchicalParsing7,Mathpad46} . 
%
%
%ASSIST \cite{AlvaradoFreedom42} uses domain knowledge, context memory and user feedback to help in understanding procedure. Domain knowledge to get a set of possible interpretations then context knowledge is used to prune out inconsistent finally the user feedback is used to correct error interoperations.
%
%The \cite{incrmentintention41} store domain knowledge in a memory like architecture where It stores the domain knowledge in long-term memory were strokes are firstly checked for possible interpolations. Context knowledge and previous interpolations are stored in short-term memory to help more accurate recognition rate. The context and domain knowledge are also used to feed rule-based systems that uses visual language rules in making the final document recognitions \cite{interpretationmechanical50}.
%
%
%&&&&&&&&&&&&&&&&oksearch 
%\subsubsection{Using speech and various other knowledge}
%\label{sec:Usingspeechandvariousotherknowledge}
%
%Multimodal systems are system that uses more than one source of input devices as input to the system. Theses systems help in providing sketch understanding with more information's and data that will help in the recognition procedure. Speech and verbal explanation of drawn symbols are most used data in multimodal system to aid sketch understanding \cite {cognitivesketch18,speechMulti27,computationalmodel16} .
%

%\subsection{Space Search}
%\label{sec:SpaceSearch}
%
%The solutions of any sketch understanding are not found until the problem of minimizing and find an efficient way to search the solution space is solved.  The solution space increase exponentially with each stroke the user draws dependably on the system. Either ways the space search problem must be addressed to properly solve the problem of sketch understanding. 
%
%\cite {EfficientAbstract39}  illustrate a new search space minimization where the recognizer can perform one of the checking for constrains between images feature. Check for partial interpretation by assigning an image feature to a model feature or the user draws delaying until more strokes. Every new stroke is drawn either a new partial interpolation is created an old interpolation is extended and cloned provided that no constrains or rule is violated.


